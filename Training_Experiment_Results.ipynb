{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CikFsKv8jaok"
      },
      "source": [
        "**Experiment details**\n",
        "9 Experiments were performed. Experiment# 1,2,5 & 7 showed precision & recall improvement and metrics for the same is shown in this notebook. \n",
        "\n",
        "**Augmentations**: random crop & random adjust contrast augmentations were applied after considering numerous options. random_adjust contrast yeilded improvement on precision & recall.\n",
        "\n",
        "**Increasing scales per octave** to 3 showed increase in precesion and recall.Further increase to 4 scales per octave did not yeild an increase in precesion and recall.\n",
        "\n",
        "**Adjusting nms score threshold **to 1e-01 did not improve the precesion and recall 1e-08 was used as nms score threshold, many small objects have low score.\n",
        "\n",
        "**Custom anchor aspect ratios** were used in experiment 7. The anchor aspect ratios were computed from ground truth of train set. Clustering were used to pick the ratios. 4 aspect ratios were used here. Using higher number of aspect ratios such as 12 reduced teh precision and recall, more ratios fitting small objects were used as the small boxes are far more greater compared to medium and large and ssd doesn't perform well on small objects.\n",
        "\n",
        "\n",
        "\n",
        "**Exp 1:**  25k steps, lr=1e-03, 2 scales per octave, cosine decay scheduler, nms score thr=1e-08, iou thr=.6, anchor_ratios=[1,.5,2]\n",
        "\n",
        "**Exp2:**\n",
        "exp2 with Augmentation\n",
        " random_adjust_contrast{\n",
        "    min_delta : .4\n",
        "    max_delta : .8\n",
        "    }\n",
        "25k steps, lr=1e-03, 2 scales per octave, cosine decay scheduler, nms score thr=1e-08, iou thr=.6, anchor_ratios=[1,.5,2]\n",
        "\n",
        "**Exp 5** increase scales per octave to 3 no augmentation used\n",
        "25k steps, lr=1e-03, 3 scales per octave, cosine decay scheduler, nms score thr=1e-08, iou thr=.6, anchor_ratios=[1,.5,2]\n",
        "\n",
        "**Exp 7**\n",
        "aspect_ratios: [0.35459628,0.86450212,1.70103675,3.30941172]\n",
        "scales_per_octave: 3\n",
        "25k steps, lr=1e-03, 3 scales per octave, cosine decay scheduler, nms score thr=1e-08, iou thr=.6, anchor_ratios=: [0.35459628,0.86450212,1.70103675,3.30941172]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bmDcS1GVjfRe"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from matplotlib.patches import Rectangle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cSXGm2Tz9dSP"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QS05mYCK2a8J"
      },
      "outputs": [],
      "source": [
        "%cd '/content/drive/MyDrive/new/TensorFlow/'\n",
        "!git clone https://github.com/tensorflow/models.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nq_l4jBLpWfX"
      },
      "source": [
        "**Installing TFOD Model Zoo API**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MEu9G1MV3EdC",
        "outputId": "be1f1f8b-2a32-43d3-fccb-d7f077b59fd8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/new/TensorFlow/models/research\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Processing /content/drive/MyDrive/new/TensorFlow/models/research\n",
            "\u001b[33m  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n",
            "   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\u001b[0m\n",
            "Collecting avro-python3\n",
            "  Downloading avro-python3-1.10.2.tar.gz (38 kB)\n",
            "Collecting apache-beam\n",
            "  Downloading apache_beam-2.40.0-cp37-cp37m-manylinux2010_x86_64.whl (10.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.9 MB 8.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (7.1.2)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (4.2.6)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (3.2.2)\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (0.29.30)\n",
            "Requirement already satisfied: contextlib2 in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (0.5.5)\n",
            "Collecting tf-slim\n",
            "  Downloading tf_slim-1.1.0-py2.py3-none-any.whl (352 kB)\n",
            "\u001b[K     |████████████████████████████████| 352 kB 73.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.15.0)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (2.0.4)\n",
            "Collecting lvis\n",
            "  Downloading lvis-0.5.3-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.4.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.3.5)\n",
            "Collecting tensorflow==2.7.0\n",
            "  Downloading https://us-python.pkg.dev/colab-wheels/public/tensorflow/tensorflow-2.7.0%2Bzzzcolab20220506150900-cp37-cp37m-linux_x86_64.whl (665.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 665.5 MB 20 kB/s \n",
            "\u001b[?25hCollecting tf-models-official==2.7.0\n",
            "  Downloading tf_models_official-2.7.0-py2.py3-none-any.whl (1.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.8 MB 55.1 MB/s \n",
            "\u001b[?25hCollecting tensorflow_io==0.23.1\n",
            "  Downloading tensorflow_io-0.23.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (23.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 23.1 MB 1.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (2.8.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0->object-detection==0.1) (1.1.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0->object-detection==0.1) (0.37.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0->object-detection==0.1) (1.1.2)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0->object-detection==0.1) (0.2.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0->object-detection==0.1) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers<3.0,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0->object-detection==0.1) (2.0)\n",
            "Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0->object-detection==0.1) (2.8.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0->object-detection==0.1) (3.3.0)\n",
            "Collecting gast<0.5.0,>=0.2.1\n",
            "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0->object-detection==0.1) (1.1.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0->object-detection==0.1) (0.26.0)\n",
            "Collecting keras\n",
            "  Downloading keras-2.7.0-py2.py3-none-any.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 77.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0->object-detection==0.1) (3.17.3)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0->object-detection==0.1) (1.21.6)\n",
            "Collecting tensorflow-estimator<2.8,~=2.7.0rc0\n",
            "  Downloading tensorflow_estimator-2.7.0-py2.py3-none-any.whl (463 kB)\n",
            "\u001b[K     |████████████████████████████████| 463 kB 89.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0->object-detection==0.1) (4.1.1)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0->object-detection==0.1) (1.14.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0->object-detection==0.1) (1.46.3)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0->object-detection==0.1) (14.0.1)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0->object-detection==0.1) (3.1.0)\n",
            "Collecting tensorflow-io-gcs-filesystem>=0.21.0\n",
            "  Downloading tensorflow_io_gcs_filesystem-0.23.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1 MB 24.4 MB/s \n",
            "\u001b[?25hCollecting tensorflow-model-optimization>=0.4.1\n",
            "  Downloading tensorflow_model_optimization-0.7.2-py2.py3-none-any.whl (237 kB)\n",
            "\u001b[K     |████████████████████████████████| 237 kB 90.3 MB/s \n",
            "\u001b[?25hCollecting py-cpuinfo>=3.3.0\n",
            "  Downloading py-cpuinfo-8.0.0.tar.gz (99 kB)\n",
            "\u001b[K     |████████████████████████████████| 99 kB 8.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.7/dist-packages (from tf-models-official==2.7.0->object-detection==0.1) (4.0.1)\n",
            "Requirement already satisfied: gin-config in /usr/local/lib/python3.7/dist-packages (from tf-models-official==2.7.0->object-detection==0.1) (0.5.0)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 72.0 MB/s \n",
            "\u001b[?25hCollecting seqeval\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[K     |████████████████████████████████| 43 kB 2.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: oauth2client in /usr/local/lib/python3.7/dist-packages (from tf-models-official==2.7.0->object-detection==0.1) (4.1.3)\n",
            "Requirement already satisfied: tensorflow-hub>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official==2.7.0->object-detection==0.1) (0.12.0)\n",
            "Collecting tensorflow-addons\n",
            "  Downloading tensorflow_addons-0.17.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 68.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-api-python-client>=1.6.7 in /usr/local/lib/python3.7/dist-packages (from tf-models-official==2.7.0->object-detection==0.1) (1.12.11)\n",
            "Collecting opencv-python-headless\n",
            "  Downloading opencv_python_headless-4.6.0.66-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (48.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 48.3 MB 229 kB/s \n",
            "\u001b[?25hCollecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 99.0 MB/s \n",
            "\u001b[?25hCollecting tensorflow-text>=2.7.0\n",
            "  Downloading tensorflow_text-2.9.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.6 MB 91.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: psutil>=5.4.3 in /usr/local/lib/python3.7/dist-packages (from tf-models-official==2.7.0->object-detection==0.1) (5.4.8)\n",
            "Collecting sacrebleu\n",
            "  Downloading sacrebleu-2.1.0-py3-none-any.whl (92 kB)\n",
            "\u001b[K     |████████████████████████████████| 92 kB 12.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: kaggle>=1.3.9 in /usr/local/lib/python3.7/dist-packages (from tf-models-official==2.7.0->object-detection==0.1) (1.5.12)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official==2.7.0->object-detection==0.1) (3.0.1)\n",
            "Requirement already satisfied: google-auth<3dev,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official==2.7.0->object-detection==0.1) (1.35.0)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.15.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official==2.7.0->object-detection==0.1) (0.17.4)\n",
            "Requirement already satisfied: google-api-core<3dev,>=1.21.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official==2.7.0->object-detection==0.1) (1.31.6)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official==2.7.0->object-detection==0.1) (0.0.4)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official==2.7.0->object-detection==0.1) (21.3)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official==2.7.0->object-detection==0.1) (57.4.0)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official==2.7.0->object-detection==0.1) (2.23.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official==2.7.0->object-detection==0.1) (1.56.2)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official==2.7.0->object-detection==0.1) (2022.1)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official==2.7.0->object-detection==0.1) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official==2.7.0->object-detection==0.1) (4.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official==2.7.0->object-detection==0.1) (0.2.8)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow==2.7.0->object-detection==0.1) (1.5.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official==2.7.0->object-detection==0.1) (2022.6.15)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official==2.7.0->object-detection==0.1) (2.8.2)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official==2.7.0->object-detection==0.1) (6.1.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official==2.7.0->object-detection==0.1) (4.64.0)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official==2.7.0->object-detection==0.1) (1.24.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=14.3->google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official==2.7.0->object-detection==0.1) (3.0.9)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official==2.7.0->object-detection==0.1) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official==2.7.0->object-detection==0.1) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official==2.7.0->object-detection==0.1) (2.10)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.7.0->object-detection==0.1) (3.3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.7.0->object-detection==0.1) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.7.0->object-detection==0.1) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.7.0->object-detection==0.1) (1.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.7.0->object-detection==0.1) (0.4.6)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow==2.7.0->object-detection==0.1) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow==2.7.0->object-detection==0.1) (4.11.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.6->tensorflow==2.7.0->object-detection==0.1) (3.8.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow==2.7.0->object-detection==0.1) (3.2.0)\n",
            "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-model-optimization>=0.4.1->tf-models-official==2.7.0->object-detection==0.1) (0.1.7)\n",
            "Collecting tensorflow-text>=2.7.0\n",
            "  Downloading tensorflow_text-2.8.2-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (4.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.9 MB 58.7 MB/s \n",
            "\u001b[?25h  Downloading tensorflow_text-2.8.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (4.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.9 MB 62.7 MB/s \n",
            "\u001b[?25h  Downloading tensorflow_text-2.7.3-cp37-cp37m-manylinux2010_x86_64.whl (4.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.9 MB 57.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: crcmod<2.0,>=1.7 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (1.7)\n",
            "Collecting requests<3.0.0dev,>=2.18.0\n",
            "  Downloading requests-2.28.1-py3-none-any.whl (62 kB)\n",
            "\u001b[K     |████████████████████████████████| 62 kB 1.7 MB/s \n",
            "\u001b[?25hCollecting dill<0.3.2,>=0.3.1.1\n",
            "  Downloading dill-0.3.1.1.tar.gz (151 kB)\n",
            "\u001b[K     |████████████████████████████████| 151 kB 102.1 MB/s \n",
            "\u001b[?25hCollecting orjson<4.0\n",
            "  Downloading orjson-3.7.6-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (272 kB)\n",
            "\u001b[K     |████████████████████████████████| 272 kB 84.2 MB/s \n",
            "\u001b[?25hCollecting hdfs<3.0.0,>=2.1.0\n",
            "  Downloading hdfs-2.7.0-py3-none-any.whl (34 kB)\n",
            "Requirement already satisfied: pydot<2,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (1.3.0)\n",
            "Collecting pymongo<4.0.0,>=3.8.0\n",
            "  Downloading pymongo-3.12.3-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (508 kB)\n",
            "\u001b[K     |████████████████████████████████| 508 kB 68.6 MB/s \n",
            "\u001b[?25hCollecting proto-plus<2,>=1.7.1\n",
            "  Downloading proto_plus-1.20.6-py3-none-any.whl (46 kB)\n",
            "\u001b[K     |████████████████████████████████| 46 kB 5.0 MB/s \n",
            "\u001b[?25hCollecting fastavro<2,>=0.23.6\n",
            "  Downloading fastavro-1.5.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3 MB 83.6 MB/s \n",
            "\u001b[?25hCollecting cloudpickle<3,>=2.1.0\n",
            "  Downloading cloudpickle-2.1.0-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: pyarrow<8.0.0,>=0.15.1 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (6.0.1)\n",
            "Requirement already satisfied: docopt in /usr/local/lib/python3.7/dist-packages (from hdfs<3.0.0,>=2.1.0->apache-beam->object-detection==0.1) (0.6.2)\n",
            "Collecting protobuf>=3.9.2\n",
            "  Downloading protobuf-3.20.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0 MB 85.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official==2.7.0->object-detection==0.1) (2.0.12)\n",
            "Requirement already satisfied: kiwisolver>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (1.4.3)\n",
            "Requirement already satisfied: cycler>=0.10.0 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (0.11.0)\n",
            "Requirement already satisfied: opencv-python>=4.1.0.25 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (4.1.2.30)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle>=1.3.9->tf-models-official==2.7.0->object-detection==0.1) (1.3)\n",
            "Collecting colorama\n",
            "  Downloading colorama-0.4.5-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from sacrebleu->tf-models-official==2.7.0->object-detection==0.1) (2022.6.2)\n",
            "Collecting portalocker\n",
            "  Downloading portalocker-2.4.0-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.7/dist-packages (from sacrebleu->tf-models-official==2.7.0->object-detection==0.1) (0.8.9)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval->tf-models-official==2.7.0->object-detection==0.1) (1.0.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official==2.7.0->object-detection==0.1) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official==2.7.0->object-detection==0.1) (1.1.0)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons->tf-models-official==2.7.0->object-detection==0.1) (2.7.1)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official==2.7.0->object-detection==0.1) (5.7.1)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official==2.7.0->object-detection==0.1) (2.3)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official==2.7.0->object-detection==0.1) (1.8.0)\n",
            "Requirement already satisfied: attrs>=18.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official==2.7.0->object-detection==0.1) (21.4.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official==2.7.0->object-detection==0.1) (0.16.0)\n",
            "Building wheels for collected packages: object-detection, py-cpuinfo, dill, avro-python3, seqeval\n",
            "  Building wheel for object-detection (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for object-detection: filename=object_detection-0.1-py3-none-any.whl size=1692493 sha256=73d97de2070621f0cd62f28214362651d0de22fba2b2f5f906a997d669ca2d2e\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-yl9jmsl8/wheels/e2/32/e0/19b848ba40c85a900715b51aa81f2998839e6e4e584033294f\n",
            "  Building wheel for py-cpuinfo (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for py-cpuinfo: filename=py_cpuinfo-8.0.0-py3-none-any.whl size=22257 sha256=ef2d74ac266ae91a43f3744868a5671ddf2753272b845e0567d736cf641f1903\n",
            "  Stored in directory: /root/.cache/pip/wheels/d2/f1/1f/041add21dc9c4220157f1bd2bd6afe1f1a49524c3396b94401\n",
            "  Building wheel for dill (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for dill: filename=dill-0.3.1.1-py3-none-any.whl size=78544 sha256=2668872f6342924f3bfedaa9a4220cc4e0379f050aceb1babee9f892c5a87f57\n",
            "  Stored in directory: /root/.cache/pip/wheels/a4/61/fd/c57e374e580aa78a45ed78d5859b3a44436af17e22ca53284f\n",
            "  Building wheel for avro-python3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for avro-python3: filename=avro_python3-1.10.2-py3-none-any.whl size=44010 sha256=48348d8a9ea311f65710c3f23e311410d0f2a296e4af5828b6c8b6fcb0c6b6c0\n",
            "  Stored in directory: /root/.cache/pip/wheels/d6/e5/b1/6b151d9b535ee50aaa6ab27d145a0104b6df02e5636f0376da\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16180 sha256=47fad66529a7b0f4b19c98a3bc40ab612aac012e5f8e21fb6308da9fdad50315\n",
            "  Stored in directory: /root/.cache/pip/wheels/05/96/ee/7cac4e74f3b19e3158dce26a20a1c86b3533c43ec72a549fd7\n",
            "Successfully built object-detection py-cpuinfo dill avro-python3 seqeval\n",
            "Installing collected packages: requests, protobuf, tensorflow-io-gcs-filesystem, tensorflow-estimator, keras, gast, tensorflow, portalocker, dill, colorama, tf-slim, tensorflow-text, tensorflow-model-optimization, tensorflow-addons, seqeval, sentencepiece, sacrebleu, pyyaml, pymongo, py-cpuinfo, proto-plus, orjson, opencv-python-headless, hdfs, fastavro, cloudpickle, tf-models-official, tensorflow-io, lvis, avro-python3, apache-beam, object-detection\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.17.3\n",
            "    Uninstalling protobuf-3.17.3:\n",
            "      Successfully uninstalled protobuf-3.17.3\n",
            "  Attempting uninstall: tensorflow-io-gcs-filesystem\n",
            "    Found existing installation: tensorflow-io-gcs-filesystem 0.26.0\n",
            "    Uninstalling tensorflow-io-gcs-filesystem-0.26.0:\n",
            "      Successfully uninstalled tensorflow-io-gcs-filesystem-0.26.0\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.8.0\n",
            "    Uninstalling tensorflow-estimator-2.8.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.8.0\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.8.0\n",
            "    Uninstalling keras-2.8.0:\n",
            "      Successfully uninstalled keras-2.8.0\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.5.3\n",
            "    Uninstalling gast-0.5.3:\n",
            "      Successfully uninstalled gast-0.5.3\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.8.2+zzzcolab20220527125636\n",
            "    Uninstalling tensorflow-2.8.2+zzzcolab20220527125636:\n",
            "      Successfully uninstalled tensorflow-2.8.2+zzzcolab20220527125636\n",
            "  Attempting uninstall: dill\n",
            "    Found existing installation: dill 0.3.5.1\n",
            "    Uninstalling dill-0.3.5.1:\n",
            "      Successfully uninstalled dill-0.3.5.1\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Attempting uninstall: pymongo\n",
            "    Found existing installation: pymongo 4.1.1\n",
            "    Uninstalling pymongo-4.1.1:\n",
            "      Successfully uninstalled pymongo-4.1.1\n",
            "  Attempting uninstall: cloudpickle\n",
            "    Found existing installation: cloudpickle 1.3.0\n",
            "    Uninstalling cloudpickle-1.3.0:\n",
            "      Successfully uninstalled cloudpickle-1.3.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "multiprocess 0.70.13 requires dill>=0.3.5.1, but you have dill 0.3.1.1 which is incompatible.\n",
            "gym 0.17.3 requires cloudpickle<1.7.0,>=1.2.0, but you have cloudpickle 2.1.0 which is incompatible.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.28.1 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed apache-beam-2.40.0 avro-python3-1.10.2 cloudpickle-2.1.0 colorama-0.4.5 dill-0.3.1.1 fastavro-1.5.2 gast-0.4.0 hdfs-2.7.0 keras-2.7.0 lvis-0.5.3 object-detection-0.1 opencv-python-headless-4.6.0.66 orjson-3.7.6 portalocker-2.4.0 proto-plus-1.20.6 protobuf-3.20.1 py-cpuinfo-8.0.0 pymongo-3.12.3 pyyaml-6.0 requests-2.28.1 sacrebleu-2.1.0 sentencepiece-0.1.96 seqeval-1.2.2 tensorflow-2.7.0+zzzcolab20220506150900 tensorflow-addons-0.17.1 tensorflow-estimator-2.7.0 tensorflow-io-0.23.1 tensorflow-io-gcs-filesystem-0.23.1 tensorflow-model-optimization-0.7.2 tensorflow-text-2.7.3 tf-models-official-2.7.0 tf-slim-1.1.0\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/MyDrive/new/TensorFlow/models/research/\n",
        "!protoc object_detection/protos/*.proto --python_out=.\n",
        "# Install TensorFlow Object Detection API.\n",
        "!cp object_detection/packages/tf2/setup.py .\n",
        "!python -m pip install ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lzXJU1oFpxzh"
      },
      "source": [
        "**Checking the GPU Assigned**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FkiUwvjeIUBf"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Enpg5PB3p26d"
      },
      "source": [
        "**Adjusting version of few libraries**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K6jpNShgfMXZ",
        "outputId": "9f96d3d4-b684-49d8-d00c-21d9dff87402"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: opencv-python-headless 4.6.0.66\n",
            "Uninstalling opencv-python-headless-4.6.0.66:\n",
            "  Would remove:\n",
            "    /usr/local/lib/python3.7/dist-packages/cv2/*\n",
            "    /usr/local/lib/python3.7/dist-packages/opencv_python_headless-4.6.0.66.dist-info/*\n",
            "    /usr/local/lib/python3.7/dist-packages/opencv_python_headless.libs/libavcodec-5896f664.so.58.134.100\n",
            "    /usr/local/lib/python3.7/dist-packages/opencv_python_headless.libs/libavformat-8ef5c7db.so.58.76.100\n",
            "    /usr/local/lib/python3.7/dist-packages/opencv_python_headless.libs/libavutil-9c768859.so.56.70.100\n",
            "    /usr/local/lib/python3.7/dist-packages/opencv_python_headless.libs/libbz2-a273e504.so.1.0.6\n",
            "    /usr/local/lib/python3.7/dist-packages/opencv_python_headless.libs/libcrypto-d21001fc.so.1.1\n",
            "    /usr/local/lib/python3.7/dist-packages/opencv_python_headless.libs/libgfortran-91cc3cb1.so.3.0.0\n",
            "    /usr/local/lib/python3.7/dist-packages/opencv_python_headless.libs/libopenblas-r0-f650aae0.3.3.so\n",
            "    /usr/local/lib/python3.7/dist-packages/opencv_python_headless.libs/libpng16-57e5e0a0.so.16.37.0\n",
            "    /usr/local/lib/python3.7/dist-packages/opencv_python_headless.libs/libquadmath-96973f99.so.0.0.0\n",
            "    /usr/local/lib/python3.7/dist-packages/opencv_python_headless.libs/libssl-c8c53640.so.1.1\n",
            "    /usr/local/lib/python3.7/dist-packages/opencv_python_headless.libs/libswresample-99364a1c.so.3.9.100\n",
            "    /usr/local/lib/python3.7/dist-packages/opencv_python_headless.libs/libswscale-e6451464.so.5.9.100\n",
            "    /usr/local/lib/python3.7/dist-packages/opencv_python_headless.libs/libvpx-f22f1483.so.7.0.0\n",
            "  Would not remove (might be manually added):\n",
            "    /usr/local/lib/python3.7/dist-packages/cv2/.libs/libQtCore-bbdab771.so.4.8.7\n",
            "    /usr/local/lib/python3.7/dist-packages/cv2/.libs/libQtGui-903938cd.so.4.8.7\n",
            "    /usr/local/lib/python3.7/dist-packages/cv2/.libs/libQtTest-1183da5d.so.4.8.7\n",
            "    /usr/local/lib/python3.7/dist-packages/cv2/.libs/libavcodec-3cdd3bd4.so.58.62.100\n",
            "    /usr/local/lib/python3.7/dist-packages/cv2/.libs/libavformat-69a63b50.so.58.35.100\n",
            "    /usr/local/lib/python3.7/dist-packages/cv2/.libs/libavutil-8e8979a8.so.56.36.100\n",
            "    /usr/local/lib/python3.7/dist-packages/cv2/.libs/libbz2-7225278b.so.1.0.3\n",
            "    /usr/local/lib/python3.7/dist-packages/cv2/.libs/libcrypto-a25ff511.so.1.1\n",
            "    /usr/local/lib/python3.7/dist-packages/cv2/.libs/libssl-fdf0b66c.so.1.1\n",
            "    /usr/local/lib/python3.7/dist-packages/cv2/.libs/libswresample-c6b3bbb9.so.3.6.100\n",
            "    /usr/local/lib/python3.7/dist-packages/cv2/.libs/libswscale-2d19f7d1.so.5.6.100\n",
            "    /usr/local/lib/python3.7/dist-packages/cv2/.libs/libvpx-c887ea55.so.6.1.0\n",
            "    /usr/local/lib/python3.7/dist-packages/cv2/.libs/libz-a147dcb0.so.1.2.3\n",
            "    /usr/local/lib/python3.7/dist-packages/cv2/cv2.cpython-37m-x86_64-linux-gnu.so\n",
            "Proceed (y/n)? y\n",
            "  Successfully uninstalled opencv-python-headless-4.6.0.66\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting opencv-python-headless==4.5.2.52\n",
            "  Downloading opencv_python_headless-4.5.2.52-cp37-cp37m-manylinux2014_x86_64.whl (38.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 38.2 MB 7.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-python-headless==4.5.2.52) (1.21.6)\n",
            "Installing collected packages: opencv-python-headless\n",
            "Successfully installed opencv-python-headless-4.5.2.52\n"
          ]
        }
      ],
      "source": [
        "!pip uninstall opencv-python-headless==4.5.5.62\n",
        "!pip install opencv-python-headless==4.5.2.52"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m0IW9I5xqAnN"
      },
      "source": [
        "**Testing the Installation of TFOD**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HTj2CZNL4V2Z",
        "outputId": "199759d0-34f4-4bc5-d757-7cc1a08509d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/new/TensorFlow/models/research/object_detection/builders/model_builder_tf2_test.py\", line 24, in <module>\n",
            "    from object_detection.builders import model_builder\n",
            "ModuleNotFoundError: No module named 'object_detection'\n"
          ]
        }
      ],
      "source": [
        "!python /content/drive/MyDrive/new/TensorFlow/models/research/object_detection/builders/model_builder_tf2_test.py"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#exp1 25k steps, lr=1e-03, 2 scales per octave, cosine decay scheduler, nms score thr=1e-08, iou thr=.6, anchor_ratios=[1,.5,2]\n",
        "metrics = coco_evaluator.evaluate()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f3PDs4Y74Bqt",
        "outputId": "72c90eaa-6fd7-4cad-81b1-44e19e466089"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Performing evaluation on 13847 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.75s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=465.63s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=19.70s).\n",
            " Average Precision Cars       (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.260\n",
            " Average Precision Pedestrian (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.108\n",
            " Average Precision Cyclist    (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.095\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.154\n",
            " Average Precision Cars       (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.439\n",
            " Average Precision Pedestrian (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.265\n",
            " Average Precision Cyclist    (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.161\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.288\n",
            " Average Precision Cars       (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.256\n",
            " Average Precision Pedestrian (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.072\n",
            " Average Precision Cyclist    (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.101\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.143\n",
            " Average Precision Cars       (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.096\n",
            " Average Precision Pedestrian (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.067\n",
            " Average Precision Cyclist    (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.012\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.058\n",
            " Average Precision Cars       (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.614\n",
            " Average Precision Pedestrian (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.408\n",
            " Average Precision Cyclist    (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.355\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.459\n",
            " Average Precision Cars       (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.834\n",
            " Average Precision Pedestrian (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.576\n",
            " Average Precision Cyclist    (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.753\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.721\n",
            " Average Recall Cars       (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.047\n",
            " Average Recall Pedestrian (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.030\n",
            " Average Recall Cyclist    (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.097\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.058\n",
            " Average Recall Cars       (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.237\n",
            " Average Recall Pedestrian (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.124\n",
            " Average Recall Cyclist    (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.147\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.169\n",
            " Average Recall Cars       (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.326\n",
            " Average Recall Pedestrian (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.186\n",
            " Average Recall Cyclist    (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.148\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.220\n",
            " Average Recall Cars       (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.190\n",
            " Average Recall Pedestrian (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.147\n",
            " Average Recall Cyclist    (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.053\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.130\n",
            " Average Recall Cars       (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.663\n",
            " Average Recall Pedestrian (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.513\n",
            " Average Recall Cyclist    (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.463\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.546\n",
            " Average Recall Cars       (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.863\n",
            " Average Recall Pedestrian (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.667\n",
            " Average Recall Cyclist    (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.778\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.770\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " #exp2 with Augmentation\n",
        " #random_adjust_contrast{\n",
        " #   min_delta : .4\n",
        " #   max_delta : .8\n",
        " #   }*/\n",
        " #25k steps, lr=1e-03, 2 scales per octave, cosine decay scheduler, nms score thr=1e-08, iou thr=.6, anchor_ratios=[1,.5,2]\n",
        " metrics = coco_evaluator.evaluate()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MwkY0IAv-h-L",
        "outputId": "6cb4ff85-72bd-41d0-d6da-d79c7013bf53"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Performing evaluation on 13847 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.74s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=465.16s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=17.72s).\n",
            " Average Precision Cars       (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.260\n",
            " Average Precision Pedestrian (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.107\n",
            " Average Precision Cyclist    (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.098\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.155\n",
            " Average Precision Cars       (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.438\n",
            " Average Precision Pedestrian (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.261\n",
            " Average Precision Cyclist    (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.168\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.289\n",
            " Average Precision Cars       (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.257\n",
            " Average Precision Pedestrian (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.073\n",
            " Average Precision Cyclist    (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.102\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.144\n",
            " Average Precision Cars       (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.097\n",
            " Average Precision Pedestrian (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.067\n",
            " Average Precision Cyclist    (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.016\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.060\n",
            " Average Precision Cars       (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.613\n",
            " Average Precision Pedestrian (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.415\n",
            " Average Precision Cyclist    (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.339\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.456\n",
            " Average Precision Cars       (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.829\n",
            " Average Precision Pedestrian (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.565\n",
            " Average Precision Cyclist    (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.746\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.713\n",
            " Average Recall Cars       (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.046\n",
            " Average Recall Pedestrian (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.032\n",
            " Average Recall Cyclist    (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.099\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.059\n",
            " Average Recall Cars       (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.236\n",
            " Average Recall Pedestrian (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.125\n",
            " Average Recall Cyclist    (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.145\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.169\n",
            " Average Recall Cars       (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.325\n",
            " Average Recall Pedestrian (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.182\n",
            " Average Recall Cyclist    (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.146\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.218\n",
            " Average Recall Cars       (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.190\n",
            " Average Recall Pedestrian (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.143\n",
            " Average Recall Cyclist    (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.056\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.130\n",
            " Average Recall Cars       (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.662\n",
            " Average Recall Pedestrian (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.516\n",
            " Average Recall Cyclist    (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.442\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.540\n",
            " Average Recall Cars       (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.859\n",
            " Average Recall Pedestrian (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.647\n",
            " Average Recall Cyclist    (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.784\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.763\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Exp 5 increase scales per octave to 3 no augmentation used\n",
        "#25k steps, lr=1e-03, 3 scales per octave, cosine decay scheduler, nms score thr=1e-08, iou thr=.6, anchor_ratios=[1,.5,2]\n",
        "metrics = coco_evaluator.evaluate()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wwjK7CwLE_IN",
        "outputId": "7d806edc-0b25-4090-9013-93e8737d734a"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Performing evaluation on 13847 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.78s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=467.01s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=17.78s).\n",
            " Average Precision Cars       (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.260\n",
            " Average Precision Pedestrian (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.110\n",
            " Average Precision Cyclist    (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.101\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.157\n",
            " Average Precision Cars       (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.437\n",
            " Average Precision Pedestrian (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.263\n",
            " Average Precision Cyclist    (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.174\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.292\n",
            " Average Precision Cars       (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.258\n",
            " Average Precision Pedestrian (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.077\n",
            " Average Precision Cyclist    (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.107\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.147\n",
            " Average Precision Cars       (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.094\n",
            " Average Precision Pedestrian (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.067\n",
            " Average Precision Cyclist    (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.017\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.059\n",
            " Average Precision Cars       (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.624\n",
            " Average Precision Pedestrian (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.430\n",
            " Average Precision Cyclist    (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.360\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.471\n",
            " Average Precision Cars       (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.843\n",
            " Average Precision Pedestrian (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.566\n",
            " Average Precision Cyclist    (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.738\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.716\n",
            " Average Recall Cars       (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.047\n",
            " Average Recall Pedestrian (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.032\n",
            " Average Recall Cyclist    (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.104\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.061\n",
            " Average Recall Cars       (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.236\n",
            " Average Recall Pedestrian (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.126\n",
            " Average Recall Cyclist    (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.156\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.173\n",
            " Average Recall Cars       (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.326\n",
            " Average Recall Pedestrian (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.184\n",
            " Average Recall Cyclist    (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.157\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.222\n",
            " Average Recall Cars       (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.187\n",
            " Average Recall Pedestrian (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.143\n",
            " Average Recall Cyclist    (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.060\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.130\n",
            " Average Recall Cars       (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.672\n",
            " Average Recall Pedestrian (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.538\n",
            " Average Recall Cyclist    (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.485\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.565\n",
            " Average Recall Cars       (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.871\n",
            " Average Recall Pedestrian (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.675\n",
            " Average Recall Cyclist    (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.768\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.772\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Exp 7\n",
        "#aspect_ratios: [0.35459628,0.86450212,1.70103675,3.30941172]\n",
        "#scales_per_octave: 3\n",
        "#25k steps, lr=1e-03, 3 scales per octave, cosine decay scheduler, nms score thr=1e-08, iou thr=.6, anchor_ratios=: [0.35459628,0.86450212,1.70103675,3.30941172]\n",
        "metrics = coco_evaluator.evaluate()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ibWbilsXL2ra",
        "outputId": "101cbd8e-bd44-4c37-8944-42c5043c5fc0"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Performing evaluation on 13847 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.75s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=474.12s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=17.55s).\n",
            " Average Precision Cars       (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.259\n",
            " Average Precision Pedestrian (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.115\n",
            " Average Precision Cyclist    (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.098\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.157\n",
            " Average Precision Cars       (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.433\n",
            " Average Precision Pedestrian (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.267\n",
            " Average Precision Cyclist    (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.163\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.288\n",
            " Average Precision Cars       (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.258\n",
            " Average Precision Pedestrian (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.087\n",
            " Average Precision Cyclist    (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.108\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.151\n",
            " Average Precision Cars       (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.093\n",
            " Average Precision Pedestrian (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.069\n",
            " Average Precision Cyclist    (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.016\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.059\n",
            " Average Precision Cars       (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.619\n",
            " Average Precision Pedestrian (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.458\n",
            " Average Precision Cyclist    (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.349\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.475\n",
            " Average Precision Cars       (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.846\n",
            " Average Precision Pedestrian (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.606\n",
            " Average Precision Cyclist    (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.718\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.724\n",
            " Average Recall Cars       (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.047\n",
            " Average Recall Pedestrian (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.033\n",
            " Average Recall Cyclist    (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.098\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.060\n",
            " Average Recall Cars       (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.235\n",
            " Average Recall Pedestrian (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.129\n",
            " Average Recall Cyclist    (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.149\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.171\n",
            " Average Recall Cars       (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.330\n",
            " Average Recall Pedestrian (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.186\n",
            " Average Recall Cyclist    (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.150\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.222\n",
            " Average Recall Cars       (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.195\n",
            " Average Recall Pedestrian (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.143\n",
            " Average Recall Cyclist    (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.055\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.131\n",
            " Average Recall Cars       (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.664\n",
            " Average Recall Pedestrian (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.554\n",
            " Average Recall Cyclist    (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.472\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.563\n",
            " Average Recall Cars       (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.874\n",
            " Average Recall Pedestrian (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.686\n",
            " Average Recall Cyclist    (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.759\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.773\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "660y97eXqO_4"
      },
      "source": [
        "**Visualization Functions**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PhdPY0ZOeAyN"
      },
      "outputs": [],
      "source": [
        "def recenter_image(image):\n",
        "    # ssd preprocessing\n",
        "    #image += [123.68, 116.779, 103.939]\n",
        "    return image\n",
        "\n",
        "def display_instances(image, bboxes, classes):\n",
        "    image = recenter_image(image)\n",
        "    #w, h, _ = image.shape\n",
        "    # resize the bboxes\n",
        "    #bboxes[:, [0, 2]] *= w\n",
        "    #bboxes[:, [1, 3]] *= h\n",
        "\n",
        "    f, ax = plt.subplots(1, figsize=(10, 10))\n",
        "    ax.imshow(image.astype(np.uint8))\n",
        "\n",
        "    for bb, cl in zip(bboxes, classes):\n",
        "        y1, x1, y2, x2 = bb\n",
        "        #print(bb)\n",
        "        rec = Rectangle((x1, y1), x2-x1, y2-y1, facecolor='none', edgecolor='r', linewidth=2)\n",
        "        ax.add_patch(rec)\n",
        "    plt.show()\n",
        "\n",
        "def display_batch(batch):\n",
        "    # get images, bboxes and classes\n",
        "    batched_images = batch[0]['image'].numpy()\n",
        "    batched_bboxes = batch[1]['groundtruth_boxes'].numpy()\n",
        "    batched_classes = batch[1]['groundtruth_classes'].numpy()\n",
        "    num_bboxes = batch[1]['num_groundtruth_boxes'].numpy()\n",
        "    #print(batched_bboxes.shape)\n",
        "    batch_size = batched_images.shape[0]\n",
        "    for idx in range(batch_size):\n",
        "      #print(batched_bboxes[idx, :num_bboxes[idx], :])\n",
        "      display_instances(batched_images[idx, ...], batched_bboxes[idx, :num_bboxes[idx], :], batched_classes[idx, ...])\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#exp7\n",
        "%cd /content/drive/MyDrive/nd013-c1-vision-starter/\n",
        "label_map_path  = '/content/drive/MyDrive/nd013-c1-vision-starter/label_map.pbtxt'\n",
        "config_path ='/content/drive/MyDrive/nd013-c1-vision-starter/experiments/exp7/training/reference/exp7_pipeline.config'\n",
        "saved_model_path = '/content/drive/MyDrive/nd013-c1-vision-starter/experiments/exp7/training/reference/exported_model/saved_model'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X0W7xLoy33f9",
        "outputId": "68fe8a58-7f5a-4476-fe00-503a077921e6"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/nd013-c1-vision-starter\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from matplotlib import animation\n",
        "from object_detection.builders.dataset_builder import build as build_dataset\n",
        "from object_detection.utils.config_util import get_configs_from_pipeline_file\n",
        "from object_detection.utils.label_map_util import create_category_index_from_labelmap\n",
        "from object_detection.utils import visualization_utils as viz_utils\n",
        "#from utils2 import get_module_logger\n",
        "\n",
        "category_index = create_category_index_from_labelmap(label_map_path,use_display_name=True)\n",
        "\n",
        "# Load saved model and build the detection function\n",
        "#logger.info(f'Loading model from {saved_model_path}')\n",
        "detect_fn = tf.saved_model.load(saved_model_path)\n",
        "\n",
        "# open config file\n",
        "#logger.info(f'Loading config from {config_path}')\n",
        "configs = get_configs_from_pipeline_file(config_path)\n",
        "eval_config = configs['eval_config']\n",
        "eval_input_config = configs['eval_input_config']\n",
        "model_config = configs['model']\n",
        "\n",
        "tf_rec_path=\"/content/drive/MyDrive/nd013-c1-vision-starter/data_new/eval/segment-4295449061847708198_3769_000_3789_000_with_camera_labels.tfrecord\"\n",
        "    # update the eval config file\n",
        "eval_input_config.tf_record_input_reader.input_path[:] = [tf_rec_path]\n",
        "\n",
        "    # build dataset\n",
        "dataset = build_dataset(eval_input_config)\n",
        "\n",
        "images = []"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2NRcG1Ab3xXs",
        "outputId": "f9d89f42-cbe3-4422-81bb-ad3fa11d69d6"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Reading unweighted datasets: ['/content/drive/MyDrive/nd013-c1-vision-starter/data_new/eval/segment-4295449061847708198_3769_000_3789_000_with_camera_labels.tfrecord']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['/content/drive/MyDrive/nd013-c1-vision-starter/data_new/eval/segment-4295449061847708198_3769_000_3789_000_with_camera_labels.tfrecord']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd '/content/drive/MyDrive/nd013-c1-vision-starter'\n",
        "from utils2 import *\n",
        "import numpy as np\n",
        "from object_detection.core import standard_fields\n",
        "from object_detection.metrics import coco_evaluation\n",
        "from object_detection.utils import tf_version\n",
        "from pycocotools import cocoeval\n",
        "\n",
        "def _get_categories_list():\n",
        "  return [{\n",
        "      'id': 1,\n",
        "      'name': 'vehicle'\n",
        "  }, {\n",
        "      'id': 2,\n",
        "      'name': 'pedestrian'\n",
        "  }, {\n",
        "      'id': 3,\n",
        "      'name': 'dummy'\n",
        "  }, {\n",
        "      'id': 4,\n",
        "      'name': 'cyclist'\n",
        "  }]\n",
        "  \n",
        "coco_evaluator = coco_evaluation.CocoDetectionEvaluator(_get_categories_list(),include_metrics_per_category=True,all_metrics_per_category=True)\n",
        "\n",
        "for idx, batch in enumerate(dataset):\n",
        "  input_tensor = batch['image']\n",
        "  image_np = input_tensor.numpy().astype(np.uint8)\n",
        "  input_tensor = input_tensor[tf.newaxis, ...]\n",
        "  detections_batch = detect_fn(input_tensor)\n",
        "  gt_bb = batch['groundtruth_boxes'].numpy()\n",
        "  gt_bb=gt_bb*640\n",
        "  gt_cls = batch['groundtruth_classes'].numpy()\n",
        "  coco_evaluator.add_single_ground_truth_image_info(\n",
        "      image_id=str(idx),\n",
        "      groundtruth_dict={\n",
        "          standard_fields.InputDataFields.groundtruth_boxes:\n",
        "          gt_bb,\n",
        "          standard_fields.InputDataFields.groundtruth_classes: gt_cls\n",
        "      })\n",
        "  num_det = detections_batch['detection_boxes'].numpy().shape[1]\n",
        "  dt_bb = np.reshape(detections_batch['detection_boxes'].numpy(),(num_det,4))\n",
        "  dt_bb=dt_bb*640\n",
        "  dt_bb_cls = np.reshape(detections_batch['detection_classes'].numpy(),num_det)\n",
        "  dt_bb_scores = np.reshape(detections_batch['detection_scores'].numpy(),(num_det))\n",
        "  coco_evaluator.add_single_detected_image_info(\n",
        "      image_id=str(idx),\n",
        "      detections_dict={\n",
        "          standard_fields.DetectionResultFields.detection_boxes:\n",
        "          dt_bb,\n",
        "          standard_fields.DetectionResultFields.detection_scores:\n",
        "          dt_bb_scores,\n",
        "          standard_fields.DetectionResultFields.detection_classes:\n",
        "          dt_bb_cls\n",
        "      })"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cXqXisKu3oXv",
        "outputId": "2447fe82-3514-4807-c022-954f4aeb9e19"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/nd013-c1-vision-starter\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vdHOvbeH-sur"
      },
      "outputs": [],
      "source": [
        "#exp5 training\n",
        "!python '/content/drive/MyDrive/nd013-c1-vision-starter/experiments/model_main_tf2.py'  --model_dir='/content/drive/MyDrive/nd013-c1-vision-starter/experiments/exp5/training/reference' --pipeline_config_path='/content/drive/MyDrive/nd013-c1-vision-starter/experiments/exp5/training/reference/exp5_pipeline.config'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#exp6 training\n",
        "!python '/content/drive/MyDrive/nd013-c1-vision-starter/experiments/model_main_tf2.py'  --model_dir='/content/drive/MyDrive/nd013-c1-vision-starter/experiments/exp6/training/reference' --pipeline_config_path='/content/drive/MyDrive/nd013-c1-vision-starter/experiments/exp6/training/reference/exp6_pipeline.config'"
      ],
      "metadata": {
        "id": "7ha1T80hwFjc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#exp7 training\n",
        "!python '/content/drive/MyDrive/nd013-c1-vision-starter/experiments/model_main_tf2.py'  --model_dir='/content/drive/MyDrive/nd013-c1-vision-starter/experiments/exp7/training/reference' --pipeline_config_path='/content/drive/MyDrive/nd013-c1-vision-starter/experiments/exp7/training/reference/exp7_pipeline.config'"
      ],
      "metadata": {
        "id": "uMh5IAhsr2Qo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#exp8 training\n",
        "!python '/content/drive/MyDrive/nd013-c1-vision-starter/experiments/model_main_tf2.py'  --model_dir='/content/drive/MyDrive/nd013-c1-vision-starter/experiments/exp8/training/reference' --pipeline_config_path='/content/drive/MyDrive/nd013-c1-vision-starter/experiments/exp8/training/reference/exp8_pipeline.config'"
      ],
      "metadata": {
        "id": "2RxpQcI4Va1s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#exp9 training\n",
        "!python '/content/drive/MyDrive/nd013-c1-vision-starter/experiments/model_main_tf2.py'  --model_dir='/content/drive/MyDrive/nd013-c1-vision-starter/experiments/exp9/training/reference' --pipeline_config_path='/content/drive/MyDrive/nd013-c1-vision-starter/experiments/exp9/training/reference/exp9_pipeline.config'"
      ],
      "metadata": {
        "id": "XAHSRTY5s5Tb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m2gdc60vy3KT"
      },
      "outputs": [],
      "source": [
        "#Export exp9  model\n",
        "%cd /content/drive/MyDrive/nd013-c1-vision-starter/experiments/\n",
        "pipeline_config_path= '/content/drive/MyDrive/nd013-c1-vision-starter/experiments/exp9/training/reference/exp9_pipeline.config'\n",
        "ckpt_dir='/content/drive/MyDrive/nd013-c1-vision-starter/experiments/exp9/training/reference/'\n",
        "exported_model='/content/drive/MyDrive/nd013-c1-vision-starter/experiments/exp9/training/reference/exported_model/'\n",
        "!python exporter_main_v2.py --input_type image_tensor --pipeline_config_path {pipeline_config_path} --trained_checkpoint_dir {ckpt_dir} --output_directory {exported_model}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qfd65rT1wuVb"
      },
      "source": [
        "**Evaluate model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Su3wZ5NKr-d",
        "outputId": "01dd7537-d7c7-4472-88ef-a8918547630d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/nd013-c1-vision-starter\n"
          ]
        }
      ],
      "source": [
        "#exp1\n",
        "%cd /content/drive/MyDrive/nd013-c1-vision-starter/\n",
        "label_map_path  = '/content/drive/MyDrive/nd013-c1-vision-starter/label_map.pbtxt'\n",
        "config_path ='/content/drive/MyDrive/nd013-c1-vision-starter/experiments/exp1/training/reference/exp1_pipeline.config'\n",
        "saved_model_path = '/content/drive/MyDrive/nd013-c1-vision-starter/experiments/exp1/training/reference/exported_model/saved_model'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VRfVWMgbw4bz"
      },
      "source": [
        "**Build Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ohjS68A6HejP",
        "outputId": "51293f2e-327f-41ea-be3f-8dc594f5b20a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Reading unweighted datasets: ['/content/drive/MyDrive/nd013-c1-vision-starter/data_new/eval/segment-3132521568089292927_2220_000_2240_000_with_camera_labels.tfrecord', '/content/drive/MyDrive/nd013-c1-vision-starter/data_new/eval/segment-4013698638848102906_7757_240_7777_240_with_camera_labels.tfrecord', '/content/drive/MyDrive/nd013-c1-vision-starter/data_new/eval/segment-4138614210962611770_2459_360_2479_360_with_camera_labels.tfrecord', '/content/drive/MyDrive/nd013-c1-vision-starter/data_new/eval/segment-4277109506993614243_1648_000_1668_000_with_camera_labels.tfrecord', '/content/drive/MyDrive/nd013-c1-vision-starter/data_new/eval/segment-4292360793125812833_3080_000_3100_000_with_camera_labels.tfrecord', '/content/drive/MyDrive/nd013-c1-vision-starter/data_new/eval/segment-4295449061847708198_3769_000_3789_000_with_camera_labels.tfrecord', '/content/drive/MyDrive/nd013-c1-vision-starter/data_new/eval/segment-4305539677513798673_2200_000_2220_000_with_camera_labels.tfrecord', '/content/drive/MyDrive/nd013-c1-vision-starter/data_new/eval/segment-4348478035380346090_1000_000_1020_000_with_camera_labels.tfrecord', '/content/drive/MyDrive/nd013-c1-vision-starter/data_new/eval/segment-4392459808686681511_5006_200_5026_200_with_camera_labels.tfrecord', '/content/drive/MyDrive/nd013-c1-vision-starter/data_new/eval/segment-4537254579383578009_3820_000_3840_000_with_camera_labels.tfrecord', '/content/drive/MyDrive/nd013-c1-vision-starter/data_new/eval/segment-4546515828974914709_922_040_942_040_with_camera_labels.tfrecord', '/content/drive/MyDrive/nd013-c1-vision-starter/data_new/eval/segment-4575961016807404107_880_000_900_000_with_camera_labels.tfrecord', '/content/drive/MyDrive/nd013-c1-vision-starter/data_new/eval/segment-4641822195449131669_380_000_400_000_with_camera_labels.tfrecord', '/content/drive/MyDrive/nd013-c1-vision-starter/data_new/eval/segment-473735159277431842_630_095_650_095_with_camera_labels.tfrecord', '/content/drive/MyDrive/nd013-c1-vision-starter/data_new/eval/segment-4747171543583769736_425_544_445_544_with_camera_labels.tfrecord', '/content/drive/MyDrive/nd013-c1-vision-starter/data_new/eval/segment-4784689467343773295_1700_000_1720_000_with_camera_labels.tfrecord', '/content/drive/MyDrive/nd013-c1-vision-starter/data_new/eval/segment-4916527289027259239_5180_000_5200_000_with_camera_labels.tfrecord', '/content/drive/MyDrive/nd013-c1-vision-starter/data_new/eval/segment-4931036732523207946_10755_600_10775_600_with_camera_labels.tfrecord', '/content/drive/MyDrive/nd013-c1-vision-starter/data_new/eval/segment-5065468048522043429_2080_000_2100_000_with_camera_labels.tfrecord', '/content/drive/MyDrive/nd013-c1-vision-starter/data_new/eval/segment-5083516879091912247_3600_000_3620_000_with_camera_labels.tfrecord', '/content/drive/MyDrive/nd013-c1-vision-starter/data_new/eval/segment-5100136784230856773_2517_300_2537_300_with_camera_labels.tfrecord', '/content/drive/MyDrive/nd013-c1-vision-starter/data_new/eval/segment-5121298817582693383_4882_000_4902_000_with_camera_labels.tfrecord', '/content/drive/MyDrive/nd013-c1-vision-starter/data_new/eval/segment-5129792222840846899_2145_000_2165_000_with_camera_labels.tfrecord', '/content/drive/MyDrive/nd013-c1-vision-starter/data_new/eval/segment-5189543236187113739_2929_000_2949_000_with_camera_labels.tfrecord', '/content/drive/MyDrive/nd013-c1-vision-starter/data_new/eval/segment-5222336716599194110_8940_000_8960_000_with_camera_labels.tfrecord', '/content/drive/MyDrive/nd013-c1-vision-starter/data_new/eval/segment-5349843997395815699_1040_000_1060_000_with_camera_labels.tfrecord', '/content/drive/MyDrive/nd013-c1-vision-starter/data_new/eval/segment-5451442719480728410_5660_000_5680_000_with_camera_labels.tfrecord', '/content/drive/MyDrive/nd013-c1-vision-starter/data_new/eval/segment-5458962501360340931_3140_000_3160_000_with_camera_labels.tfrecord', '/content/drive/MyDrive/nd013-c1-vision-starter/data_new/eval/segment-5468483805452515080_4540_000_4560_000_with_camera_labels.tfrecord', '/content/drive/MyDrive/nd013-c1-vision-starter/data_new/eval/segment-550171902340535682_2640_000_2660_000_with_camera_labels.tfrecord', '/content/drive/MyDrive/nd013-c1-vision-starter/data_new/eval/segment-5525943706123287091_4100_000_4120_000_with_camera_labels.tfrecord', '/content/drive/MyDrive/nd013-c1-vision-starter/data_new/eval/segment-5572351910320677279_3980_000_4000_000_with_camera_labels.tfrecord', '/content/drive/MyDrive/nd013-c1-vision-starter/data_new/eval/segment-5576800480528461086_1000_000_1020_000_with_camera_labels.tfrecord', '/content/drive/MyDrive/nd013-c1-vision-starter/data_new/eval/segment-5602237689147924753_760_000_780_000_with_camera_labels.tfrecord', '/content/drive/MyDrive/nd013-c1-vision-starter/data_new/eval/segment-5691636094473163491_6889_470_6909_470_with_camera_labels.tfrecord', '/content/drive/MyDrive/nd013-c1-vision-starter/data_new/eval/segment-574762194520856849_1660_000_1680_000_with_camera_labels.tfrecord', '/content/drive/MyDrive/nd013-c1-vision-starter/data_new/eval/segment-580580436928611523_792_500_812_500_with_camera_labels.tfrecord', '/content/drive/MyDrive/nd013-c1-vision-starter/data_new/eval/segment-5835049423600303130_180_000_200_000_with_camera_labels.tfrecord', '/content/drive/MyDrive/nd013-c1-vision-starter/data_new/eval/segment-5870668058140631588_1180_000_1200_000_with_camera_labels.tfrecord', '/content/drive/MyDrive/nd013-c1-vision-starter/data_new/eval/segment-5973788713714489548_2179_770_2199_770_with_camera_labels.tfrecord', '/content/drive/MyDrive/nd013-c1-vision-starter/data_new/eval/segment-6148393791213790916_4960_000_4980_000_with_camera_labels.tfrecord', '/content/drive/MyDrive/nd013-c1-vision-starter/data_new/eval/segment-6150191934425217908_2747_800_2767_800_with_camera_labels.tfrecord', '/content/drive/MyDrive/nd013-c1-vision-starter/data_new/eval/segment-616184888931414205_2020_000_2040_000_with_camera_labels.tfrecord', '/content/drive/MyDrive/nd013-c1-vision-starter/data_new/eval/segment-6193696614129429757_2420_000_2440_000_with_camera_labels.tfrecord', '/content/drive/MyDrive/nd013-c1-vision-starter/data_new/eval/segment-6229371035421550389_2220_000_2240_000_with_camera_labels.tfrecord', '/content/drive/MyDrive/nd013-c1-vision-starter/data_new/eval/segment-6290334089075942139_1340_000_1360_000_with_camera_labels.tfrecord', '/content/drive/MyDrive/nd013-c1-vision-starter/data_new/eval/segment-634378055350569306_280_000_300_000_with_camera_labels.tfrecord', '/content/drive/MyDrive/nd013-c1-vision-starter/data_new/eval/segment-6378340771722906187_1120_000_1140_000_with_camera_labels.tfrecord', '/content/drive/MyDrive/nd013-c1-vision-starter/data_new/eval/segment-6386303598440879824_1520_000_1540_000_with_camera_labels.tfrecord', '/content/drive/MyDrive/nd013-c1-vision-starter/data_new/eval/segment-6433401807220119698_4560_000_4580_000_with_camera_labels.tfrecord', '/content/drive/MyDrive/nd013-c1-vision-starter/data_new/eval/segment-6561206763751799279_2348_600_2368_600_with_camera_labels.tfrecord', '/content/drive/MyDrive/nd013-c1-vision-starter/data_new/eval/segment-6674547510992884047_1560_000_1580_000_with_camera_labels.tfrecord', '/content/drive/MyDrive/nd013-c1-vision-starter/data_new/eval/segment-6763005717101083473_3880_000_3900_000_with_camera_labels.tfrecord', '/content/drive/MyDrive/nd013-c1-vision-starter/data_new/eval/segment-6771783338734577946_6105_840_6125_840_with_camera_labels.tfrecord', '/content/drive/MyDrive/nd013-c1-vision-starter/data_new/eval/segment-6771922013310347577_4249_290_4269_290_with_camera_labels.tfrecord', '/content/drive/MyDrive/nd013-c1-vision-starter/data_new/eval/segment-6791933003490312185_2607_000_2627_000_with_camera_labels.tfrecord', '/content/drive/MyDrive/nd013-c1-vision-starter/data_new/eval/segment-6799055159715949496_2503_000_2523_000_with_camera_labels.tfrecord', '/content/drive/MyDrive/nd013-c1-vision-starter/data_new/eval/segment-6935841224766931310_2770_310_2790_310_with_camera_labels.tfrecord', '/content/drive/MyDrive/nd013-c1-vision-starter/data_new/eval/segment-7000927478052605119_1052_330_1072_330_with_camera_labels.tfrecord', '/content/drive/MyDrive/nd013-c1-vision-starter/data_new/eval/segment-7007702792982559244_4400_000_4420_000_with_camera_labels.tfrecord', '/content/drive/MyDrive/nd013-c1-vision-starter/data_new/eval/segment-7019385869759035132_4270_850_4290_850_with_camera_labels.tfrecord', '/content/drive/MyDrive/nd013-c1-vision-starter/data_new/eval/segment-7187601925763611197_4384_300_4404_300_with_camera_labels.tfrecord', '/content/drive/MyDrive/nd013-c1-vision-starter/data_new/eval/segment-7239123081683545077_4044_370_4064_370_with_camera_labels.tfrecord', '/content/drive/MyDrive/nd013-c1-vision-starter/data_new/eval/segment-7290499689576448085_3960_000_3980_000_with_camera_labels.tfrecord', '/content/drive/MyDrive/nd013-c1-vision-starter/data_new/eval/segment-7344536712079322768_1360_000_1380_000_with_camera_labels.tfrecord', '/content/drive/MyDrive/nd013-c1-vision-starter/data_new/eval/segment-7440437175443450101_94_000_114_000_with_camera_labels.tfrecord', '/content/drive/MyDrive/nd013-c1-vision-starter/data_new/eval/segment-7458568461947999548_700_000_720_000_with_camera_labels.tfrecord', '/content/drive/MyDrive/nd013-c1-vision-starter/data_new/eval/segment-7466751345307077932_585_000_605_000_with_camera_labels.tfrecord', '/content/drive/MyDrive/nd013-c1-vision-starter/data_new/eval/segment-7517545172000568481_2325_000_2345_000_with_camera_labels.tfrecord', '/content/drive/MyDrive/nd013-c1-vision-starter/data_new/eval/segment-7543690094688232666_4945_350_4965_350_with_camera_labels.tfrecord', '/content/drive/MyDrive/nd013-c1-vision-starter/data_new/eval/segment-7554208726220851641_380_000_400_000_with_camera_labels.tfrecord', '/content/drive/MyDrive/nd013-c1-vision-starter/data_new/eval/segment-7566697458525030390_1440_000_1460_000_with_camera_labels.tfrecord']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['/content/drive/MyDrive/nd013-c1-vision-starter/data_new/eval/segment-3132521568089292927_2220_000_2240_000_with_camera_labels.tfrecord', '/content/drive/MyDrive/nd013-c1-vision-starter/data_new/eval/segment-4013698638848102906_7757_240_7777_240_with_camera_labels.tfrecord', '/content/drive/MyDrive/nd013-c1-vision-starter/data_new/eval/segment-4138614210962611770_2459_360_2479_360_with_camera_labels.tfrecord', '/content/drive/MyDrive/nd013-c1-vision-starter/data_new/eval/segment-4277109506993614243_1648_000_1668_000_with_camera_labels.tfrecord', '/content/drive/MyDrive/nd013-c1-vision-starter/data_new/eval/segment-4292360793125812833_3080_000_3100_000_with_camera_labels.tfrecord', '/content/drive/MyDrive/nd013-c1-vision-starter/data_new/eval/segment-4295449061847708198_3769_000_3789_000_with_camera_labels.tfrecord', '/content/drive/MyDrive/nd013-c1-vision-starter/data_new/eval/segment-4305539677513798673_2200_000_2220_000_with_camera_labels.tfrecord', '/content/drive/MyDrive/nd013-c1-vision-starter/data_new/eval/segment-4348478035380346090_1000_000_1020_000_with_camera_labels.tfrecord', '/content/drive/MyDrive/nd013-c1-vision-starter/data_new/eval/segment-4392459808686681511_5006_200_5026_200_with_camera_labels.tfrecord', '/content/drive/MyDrive/nd013-c1-vision-starter/data_new/eval/segment-4537254579383578009_3820_000_3840_000_with_camera_labels.tfrecord', '/content/drive/MyDrive/nd013-c1-vision-starter/data_new/eval/segment-4546515828974914709_922_040_942_040_with_camera_labels.tfrecord', '/content/drive/MyDrive/nd013-c1-vision-starter/data_new/eval/segment-4575961016807404107_880_000_900_000_with_camera_labels.tfrecord', '/content/drive/MyDrive/nd013-c1-vision-starter/data_new/eval/segment-4641822195449131669_380_000_400_000_with_camera_labels.tfrecord', '/content/drive/MyDrive/nd013-c1-vision-starter/data_new/eval/segment-473735159277431842_630_095_650_095_with_camera_labels.tfrecord', '/content/drive/MyDrive/nd013-c1-vision-starter/data_new/eval/segment-4747171543583769736_425_544_445_544_with_camera_labels.tfrecord', '/content/drive/MyDrive/nd013-c1-vision-starter/data_new/eval/segment-4784689467343773295_1700_000_1720_000_with_camera_labels.tfrecord', '/content/drive/MyDrive/nd013-c1-vision-starter/data_new/eval/segment-4916527289027259239_5180_000_5200_000_with_camera_labels.tfrecord', '/content/drive/MyDrive/nd013-c1-vision-starter/data_new/eval/segment-4931036732523207946_10755_600_10775_600_with_camera_labels.tfrecord', '/content/drive/MyDrive/nd013-c1-vision-starter/data_new/eval/segment-5065468048522043429_2080_000_2100_000_with_camera_labels.tfrecord', '/content/drive/MyDrive/nd013-c1-vision-starter/data_new/eval/segment-5083516879091912247_3600_000_3620_000_with_camera_labels.tfrecord', '/content/drive/MyDrive/nd013-c1-vision-starter/data_new/eval/segment-5100136784230856773_2517_300_2537_300_with_camera_labels.tfrecord', '/content/drive/MyDrive/nd013-c1-vision-starter/data_new/eval/segment-5121298817582693383_4882_000_4902_000_with_camera_labels.tfrecord', '/content/drive/MyDrive/nd013-c1-vision-starter/data_new/eval/segment-5129792222840846899_2145_000_2165_000_with_camera_labels.tfrecord', '/content/drive/MyDrive/nd013-c1-vision-starter/data_new/eval/segment-5189543236187113739_2929_000_2949_000_with_camera_labels.tfrecord', '/content/drive/MyDrive/nd013-c1-vision-starter/data_new/eval/segment-5222336716599194110_8940_000_8960_000_with_camera_labels.tfrecord', '/content/drive/MyDrive/nd013-c1-vision-starter/data_new/eval/segment-5349843997395815699_1040_000_1060_000_with_camera_labels.tfrecord', '/content/drive/MyDrive/nd013-c1-vision-starter/data_new/eval/segment-5451442719480728410_5660_000_5680_000_with_camera_labels.tfrecord', '/content/drive/MyDrive/nd013-c1-vision-starter/data_new/eval/segment-5458962501360340931_3140_000_3160_000_with_camera_labels.tfrecord', '/content/drive/MyDrive/nd013-c1-vision-starter/data_new/eval/segment-5468483805452515080_4540_000_4560_000_with_camera_labels.tfrecord', '/content/drive/MyDrive/nd013-c1-vision-starter/data_new/eval/segment-550171902340535682_2640_000_2660_000_with_camera_labels.tfrecord', '/content/drive/MyDrive/nd013-c1-vision-starter/data_new/eval/segment-5525943706123287091_4100_000_4120_000_with_camera_labels.tfrecord', '/content/drive/MyDrive/nd013-c1-vision-starter/data_new/eval/segment-5572351910320677279_3980_000_4000_000_with_camera_labels.tfrecord', '/content/drive/MyDrive/nd013-c1-vision-starter/data_new/eval/segment-5576800480528461086_1000_000_1020_000_with_camera_labels.tfrecord', '/content/drive/MyDrive/nd013-c1-vision-starter/data_new/eval/segment-5602237689147924753_760_000_780_000_with_camera_labels.tfrecord', '/content/drive/MyDrive/nd013-c1-vision-starter/data_new/eval/segment-5691636094473163491_6889_470_6909_470_with_camera_labels.tfrecord', '/content/drive/MyDrive/nd013-c1-vision-starter/data_new/eval/segment-574762194520856849_1660_000_1680_000_with_camera_labels.tfrecord', '/content/drive/MyDrive/nd013-c1-vision-starter/data_new/eval/segment-580580436928611523_792_500_812_500_with_camera_labels.tfrecord', '/content/drive/MyDrive/nd013-c1-vision-starter/data_new/eval/segment-5835049423600303130_180_000_200_000_with_camera_labels.tfrecord', '/content/drive/MyDrive/nd013-c1-vision-starter/data_new/eval/segment-5870668058140631588_1180_000_1200_000_with_camera_labels.tfrecord', '/content/drive/MyDrive/nd013-c1-vision-starter/data_new/eval/segment-5973788713714489548_2179_770_2199_770_with_camera_labels.tfrecord', '/content/drive/MyDrive/nd013-c1-vision-starter/data_new/eval/segment-6148393791213790916_4960_000_4980_000_with_camera_labels.tfrecord', '/content/drive/MyDrive/nd013-c1-vision-starter/data_new/eval/segment-6150191934425217908_2747_800_2767_800_with_camera_labels.tfrecord', '/content/drive/MyDrive/nd013-c1-vision-starter/data_new/eval/segment-616184888931414205_2020_000_2040_000_with_camera_labels.tfrecord', '/content/drive/MyDrive/nd013-c1-vision-starter/data_new/eval/segment-6193696614129429757_2420_000_2440_000_with_camera_labels.tfrecord', '/content/drive/MyDrive/nd013-c1-vision-starter/data_new/eval/segment-6229371035421550389_2220_000_2240_000_with_camera_labels.tfrecord', '/content/drive/MyDrive/nd013-c1-vision-starter/data_new/eval/segment-6290334089075942139_1340_000_1360_000_with_camera_labels.tfrecord', '/content/drive/MyDrive/nd013-c1-vision-starter/data_new/eval/segment-634378055350569306_280_000_300_000_with_camera_labels.tfrecord', '/content/drive/MyDrive/nd013-c1-vision-starter/data_new/eval/segment-6378340771722906187_1120_000_1140_000_with_camera_labels.tfrecord', '/content/drive/MyDrive/nd013-c1-vision-starter/data_new/eval/segment-6386303598440879824_1520_000_1540_000_with_camera_labels.tfrecord', '/content/drive/MyDrive/nd013-c1-vision-starter/data_new/eval/segment-6433401807220119698_4560_000_4580_000_with_camera_labels.tfrecord', '/content/drive/MyDrive/nd013-c1-vision-starter/data_new/eval/segment-6561206763751799279_2348_600_2368_600_with_camera_labels.tfrecord', '/content/drive/MyDrive/nd013-c1-vision-starter/data_new/eval/segment-6674547510992884047_1560_000_1580_000_with_camera_labels.tfrecord', '/content/drive/MyDrive/nd013-c1-vision-starter/data_new/eval/segment-6763005717101083473_3880_000_3900_000_with_camera_labels.tfrecord', '/content/drive/MyDrive/nd013-c1-vision-starter/data_new/eval/segment-6771783338734577946_6105_840_6125_840_with_camera_labels.tfrecord', '/content/drive/MyDrive/nd013-c1-vision-starter/data_new/eval/segment-6771922013310347577_4249_290_4269_290_with_camera_labels.tfrecord', '/content/drive/MyDrive/nd013-c1-vision-starter/data_new/eval/segment-6791933003490312185_2607_000_2627_000_with_camera_labels.tfrecord', '/content/drive/MyDrive/nd013-c1-vision-starter/data_new/eval/segment-6799055159715949496_2503_000_2523_000_with_camera_labels.tfrecord', '/content/drive/MyDrive/nd013-c1-vision-starter/data_new/eval/segment-6935841224766931310_2770_310_2790_310_with_camera_labels.tfrecord', '/content/drive/MyDrive/nd013-c1-vision-starter/data_new/eval/segment-7000927478052605119_1052_330_1072_330_with_camera_labels.tfrecord', '/content/drive/MyDrive/nd013-c1-vision-starter/data_new/eval/segment-7007702792982559244_4400_000_4420_000_with_camera_labels.tfrecord', '/content/drive/MyDrive/nd013-c1-vision-starter/data_new/eval/segment-7019385869759035132_4270_850_4290_850_with_camera_labels.tfrecord', '/content/drive/MyDrive/nd013-c1-vision-starter/data_new/eval/segment-7187601925763611197_4384_300_4404_300_with_camera_labels.tfrecord', '/content/drive/MyDrive/nd013-c1-vision-starter/data_new/eval/segment-7239123081683545077_4044_370_4064_370_with_camera_labels.tfrecord', '/content/drive/MyDrive/nd013-c1-vision-starter/data_new/eval/segment-7290499689576448085_3960_000_3980_000_with_camera_labels.tfrecord', '/content/drive/MyDrive/nd013-c1-vision-starter/data_new/eval/segment-7344536712079322768_1360_000_1380_000_with_camera_labels.tfrecord', '/content/drive/MyDrive/nd013-c1-vision-starter/data_new/eval/segment-7440437175443450101_94_000_114_000_with_camera_labels.tfrecord', '/content/drive/MyDrive/nd013-c1-vision-starter/data_new/eval/segment-7458568461947999548_700_000_720_000_with_camera_labels.tfrecord', '/content/drive/MyDrive/nd013-c1-vision-starter/data_new/eval/segment-7466751345307077932_585_000_605_000_with_camera_labels.tfrecord', '/content/drive/MyDrive/nd013-c1-vision-starter/data_new/eval/segment-7517545172000568481_2325_000_2345_000_with_camera_labels.tfrecord', '/content/drive/MyDrive/nd013-c1-vision-starter/data_new/eval/segment-7543690094688232666_4945_350_4965_350_with_camera_labels.tfrecord', '/content/drive/MyDrive/nd013-c1-vision-starter/data_new/eval/segment-7554208726220851641_380_000_400_000_with_camera_labels.tfrecord', '/content/drive/MyDrive/nd013-c1-vision-starter/data_new/eval/segment-7566697458525030390_1440_000_1460_000_with_camera_labels.tfrecord']\n",
            "INFO:tensorflow:Number of filenames to read: 72\n",
            "WARNING:tensorflow:`shuffle` is false, but the input data stream is still slightly shuffled since `num_readers` > 1.\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from matplotlib import animation\n",
        "from object_detection.builders.dataset_builder import build as build_dataset\n",
        "from object_detection.utils.config_util import get_configs_from_pipeline_file\n",
        "from object_detection.utils.label_map_util import create_category_index_from_labelmap\n",
        "from object_detection.utils import visualization_utils as viz_utils\n",
        "#from utils2 import get_module_logger\n",
        "\n",
        "category_index = create_category_index_from_labelmap(label_map_path,use_display_name=True)\n",
        "\n",
        "# Load saved model and build the detection function\n",
        "#logger.info(f'Loading model from {saved_model_path}')\n",
        "detect_fn = tf.saved_model.load(saved_model_path)\n",
        "\n",
        "# open config file\n",
        "#logger.info(f'Loading config from {config_path}')\n",
        "configs = get_configs_from_pipeline_file(config_path)\n",
        "eval_config = configs['eval_config']\n",
        "eval_input_config = configs['eval_input_config']\n",
        "model_config = configs['model']\n",
        "#tf_rec_path=\"/content/drive/MyDrive/nd013-c1-vision-starter/data_new/train/segment-10023947602400723454_1120_000_1140_000_with_camera_labels.tfrecord\"\n",
        "    # update the eval config file\n",
        "#eval_input_config.tf_record_input_reader.input_path[:] = [tf_rec_path]\n",
        "\n",
        "    # build dataset\n",
        "dataset = build_dataset(eval_input_config)\n",
        "\n",
        "images = []\n",
        "#logger.info(f'Inference on {tf_record_path}')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "zRVf1FWv6dFC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd '/content/drive/MyDrive/nd013-c1-vision-starter'\n",
        "from utils2 import *\n",
        "import numpy as np\n",
        "from object_detection.core import standard_fields\n",
        "from object_detection.metrics import coco_evaluation\n",
        "from object_detection.utils import tf_version\n",
        "from pycocotools import cocoeval\n",
        "\n",
        "def _get_categories_list():\n",
        "  return [{\n",
        "      'id': 1,\n",
        "      'name': 'vehicle'\n",
        "  }, {\n",
        "      'id': 2,\n",
        "      'name': 'pedestrian'\n",
        "  }, {\n",
        "      'id': 3,\n",
        "      'name': 'dummy'\n",
        "  }, {\n",
        "      'id': 4,\n",
        "      'name': 'cyclist'\n",
        "  }]\n",
        "  \n",
        "coco_evaluator = coco_evaluation.CocoDetectionEvaluator(_get_categories_list(),include_metrics_per_category=False,all_metrics_per_category=False)\n",
        "for idx, batch in enumerate(dataset):\n",
        "  input_tensor = batch['image']\n",
        "  image_np = input_tensor.numpy().astype(np.uint8)\n",
        "  input_tensor = input_tensor[tf.newaxis, ...]\n",
        "  detections_batch = detect_fn(input_tensor)\n",
        "  gt_bb = batch['groundtruth_boxes'].numpy()\n",
        "  gt_bb=gt_bb*640\n",
        "  gt_cls = batch['groundtruth_classes'].numpy()\n",
        "  coco_evaluator.add_single_ground_truth_image_info(\n",
        "      image_id=str(idx),\n",
        "      groundtruth_dict={\n",
        "          standard_fields.InputDataFields.groundtruth_boxes:\n",
        "          gt_bb,\n",
        "          standard_fields.InputDataFields.groundtruth_classes: gt_cls\n",
        "      })\n",
        "  num_det = detections_batch['detection_boxes'].numpy().shape[1]\n",
        "  dt_bb = np.reshape(detections_batch['detection_boxes'].numpy(),(num_det,4))\n",
        "  dt_bb=dt_bb*640\n",
        "  dt_bb_cls = np.reshape(detections_batch['detection_classes'].numpy(),num_det)\n",
        "  dt_bb_scores = np.reshape(detections_batch['detection_scores'].numpy(),(num_det))\n",
        "  coco_evaluator.add_single_detected_image_info(\n",
        "      image_id=str(idx),\n",
        "      detections_dict={\n",
        "          standard_fields.DetectionResultFields.detection_boxes:\n",
        "          dt_bb,\n",
        "          standard_fields.DetectionResultFields.detection_scores:\n",
        "          dt_bb_scores,\n",
        "          standard_fields.DetectionResultFields.detection_classes:\n",
        "          dt_bb_cls\n",
        "      })"
      ],
      "metadata": {
        "id": "BjRHK2Z3N_G8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wMOxA9mjQkVn"
      },
      "source": [
        "**Anchor box aspect ratio calculation from ground truth of train dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IuW5Z1VEzyO6"
      },
      "outputs": [],
      "source": [
        "from object_detection.core import standard_fields\n",
        "from object_detection.metrics import coco_evaluation\n",
        "from object_detection.utils import tf_version\n",
        "#from pycocotools import cocoeval\n",
        "def _get_categories_list():\n",
        "  return [{\n",
        "      'id': 1,\n",
        "      'name': 'vehicle'\n",
        "  }, {\n",
        "      'id': 2,\n",
        "      'name': 'pedestrian'\n",
        "  }, {\n",
        "      'id': 3,\n",
        "      'name': 'dummy'\n",
        "  }, {\n",
        "      'id': 4,\n",
        "      'name': 'cyclist'\n",
        "  }]\n",
        "\n",
        "coco_evaluator = coco_evaluation.CocoDetectionEvaluator(_get_categories_list(),include_metrics_per_category=True,all_metrics_per_category=True)\n",
        "a_ratios_i = []\n",
        "a_ratios_m = []\n",
        "a_ratios_l = []\n",
        "l_sum=0\n",
        "w_sum=0\n",
        "cars=0\n",
        "peds=0\n",
        "bcyc=0\n",
        "for idx, batch in enumerate(dataset):\n",
        "  #print(\"Index:\",idx)\n",
        "  #print(\"\\n\")\n",
        "  input_tensor = batch['image']\n",
        "  image_np = input_tensor.numpy().astype(np.uint8)\n",
        "  input_tensor = input_tensor[tf.newaxis, ...]\n",
        "  #detections_batch = detect_fn(input_tensor)\n",
        "  #gt_bb = example['groundtruth_boxes'].numpy()\n",
        "  gt_bb = batch['groundtruth_boxes'].numpy()\n",
        "  gt_bb_cal = gt_bb*640\n",
        "  l = gt_bb_cal[:,2] - gt_bb_cal[:,0]\n",
        "  \n",
        "  l_sum+=l.shape[0]\n",
        "  #print(\"\\n\")\n",
        "  #print(\"not small length\",l[l[:]>128].shape[0])\n",
        "  w = gt_bb_cal[:,3] - gt_bb_cal[:,1]\n",
        "  p=l*w\n",
        "\n",
        "  s_i=p<32*32\n",
        "  s_l=p>96*96\n",
        "  s_m=~(s_i+s_l)\n",
        "\n",
        "  w_sum+=w.shape[0]\n",
        "\n",
        "  a_i=w[s_i]/l[s_i]\n",
        "  a_m=w[s_m]/l[s_m]\n",
        "  a_l=w[s_l]/l[s_l]\n",
        "  a_ratios_i=np.concatenate((a_ratios_i,a_i),axis=0)\n",
        "  a_ratios_m=np.concatenate((a_ratios_m,a_m),axis=0)\n",
        "  a_ratios_l=np.concatenate((a_ratios_l,a_l),axis=0)\n",
        "\n",
        "  gt_cls = batch['groundtruth_classes'].numpy()\n",
        "  cars+=gt_cls[gt_cls[:]==1].shape[0]\n",
        "  peds+=gt_cls[gt_cls[:]==2].shape[0]\n",
        "  bcyc+=gt_cls[gt_cls[:]==4].shape[0]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MhoqEyd4QZtk"
      },
      "source": [
        "**Anchor box Aspect ratio calculation using k means clustering**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wKTf-f9IQugw"
      },
      "outputs": [],
      "source": [
        "from sklearn.cluster import KMeans\n",
        "def get_centers(a_ratios,n_clusters):\n",
        "  a=a_ratios.reshape(-1, 1)\n",
        "  kmeans = KMeans(n_clusters=n_clusters)\n",
        "  kmeans.fit(a)\n",
        "  y_kmeans = kmeans.predict(a)\n",
        "  return kmeans.cluster_centers_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J92OOo71qI5x"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "def plot_elbow(a_ratios):\n",
        "  from sklearn.cluster import KMeans\n",
        "  a=a_ratios.reshape(-1, 1)\n",
        "  # step 1\n",
        "  sse = {} \n",
        "  for k in range(1, 10):\n",
        "    kmeans = KMeans(n_clusters = k, max_iter = 1000, random_state = 1).fit(a)\n",
        "    sse[k] = kmeans.inertia_     # Use inertia attribute from the clustering object and store the inertia value for that K\n",
        "\n",
        "    # step 3\n",
        "  plt.figure()\n",
        "\n",
        "  plt.plot(list(sse.keys()), list(sse.values()), 'bx-')\n",
        "\n",
        "  plt.xlabel(\"Number of cluster\")\n",
        "\n",
        "  plt.ylabel(\"SSE\")\n",
        "\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Yqu5ieErtI-"
      },
      "outputs": [],
      "source": [
        "plot_elbow(a_ratios_i)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot_elbow(a_ratios_ml)"
      ],
      "metadata": {
        "id": "EdmxR21UoB7N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a_ratios_i.shape"
      ],
      "metadata": {
        "id": "L9i11IMNrbLe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a_ratios_m.shape"
      ],
      "metadata": {
        "id": "agFVRHvprfMJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a_ratios_l.shape"
      ],
      "metadata": {
        "id": "iVqtp4JmrhSL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zdgSG3BXZerP"
      },
      "outputs": [],
      "source": [
        "get_centers(a_ratios_i,3)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "get_centers(a_ratios_i,4)"
      ],
      "metadata": {
        "id": "bJSy0pAkpHHR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4pqCa5DbZs34"
      },
      "outputs": [],
      "source": [
        "get_centers(a_ratios_ml,3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ChcVyl-xctrE"
      },
      "outputs": [],
      "source": [
        "#train\n",
        "get_centers(a_ratios_m)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0GYZsOQvZwJr"
      },
      "outputs": [],
      "source": [
        "get_centers(a_ratios_l)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wxyf3b0qc2Bx"
      },
      "outputs": [],
      "source": [
        "#train\n",
        "get_centers(a_ratios_i,4)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a_ratios_ml=np.concatenate((a_ratios_l,a_ratios_m),axis=0)"
      ],
      "metadata": {
        "id": "jN75qBqYkmMV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_centers(a_ratios_l)"
      ],
      "metadata": {
        "id": "Tw1LckwCkuHb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import KMeans\n",
        "a=a_ratios_ml.reshape(-1, 1)\n",
        "# step 1\n",
        "sse = {} \n",
        "for k in range(1, 10):\n",
        "    kmeans = KMeans(n_clusters = k, max_iter = 1000, random_state = 1).fit(a)\n",
        "    sse[k] = kmeans.inertia_     # Use inertia attribute from the clustering object and store the inertia value for that K\n",
        "\n",
        "# step 3\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(list(sse.keys()), list(sse.values()), 'bx-')\n",
        "\n",
        "plt.xlabel(\"Number of cluster\")\n",
        "\n",
        "plt.ylabel(\"SSE\")\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ifDxsmahlD_P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_centers(a_ratios_l)"
      ],
      "metadata": {
        "id": "O2uc-qnTlbSr"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "Training_Experiment Results.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}